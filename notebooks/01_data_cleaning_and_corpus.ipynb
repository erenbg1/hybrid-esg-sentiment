{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d3a605-9880-4c12-86e6-516c4e801bca",
   "metadata": {},
   "source": [
    "### Extracting the pdfs into .txt ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3dadc7-394c-4533-b3f8-2ea572ef0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: HSBC 2024.pdf -> data/raw_reports/HSBC 2024.txt\n",
      "Extracted: HSBC 2022.pdf -> data/raw_reports/HSBC 2022.txt\n",
      "Extracted: HSBC 2023.pdf -> data/raw_reports/HSBC 2023.txt\n",
      "Extracted: Nestle 2024.pdf -> data/raw_reports/Nestle 2024.txt\n",
      "Extracted: Nestle 2023.pdf -> data/raw_reports/Nestle 2023.txt\n",
      "Extracted: Nestle 2022.pdf -> data/raw_reports/Nestle 2022.txt\n",
      "Extracted: Google 2024.pdf -> data/raw_reports/Google 2024.txt\n",
      "Extracted: Google 2022.pdf -> data/raw_reports/Google 2022.txt\n",
      "Extracted: Google 2023.pdf -> data/raw_reports/Google 2023.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "\n",
    "input_dir = \"Datasets\"\n",
    "output_dir = \"data/raw_reports/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_dir, file)\n",
    "        txt_path = os.path.join(output_dir, file.replace(\".pdf\", \".txt\"))\n",
    "        \n",
    "        with pdfplumber.open(pdf_path) as pdf, open(txt_path, \"w\", encoding=\"utf-8\") as out:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    out.write(text + \"\\n\")\n",
    "        \n",
    "        print(f\"Extracted: {file} -> {txt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa618ba-dd99-4487-95f0-8cd236e65b97",
   "metadata": {},
   "source": [
    "### Cleaning all the extracted .txt files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82da7778-f332-4c33-80af-1462508287d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning completed. Output directory: data/cleaned_v2\n"
     ]
    }
   ],
   "source": [
    "import os, re, unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path(\"data\")\n",
    "input_dir = base / \"raw_reports\"     # points to data/raw_reports/C\n",
    "output_dir = base / \"cleaned_v2\"     # cleaned files will be written here\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Replacement tables\n",
    "LIGATURES = {\n",
    "    \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬀ\": \"ff\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\",\n",
    "    \"’\": \"'\", \"‘\": \"'\", \"“\": '\"', \"”\": '\"',\n",
    "    \"‐\": \"-\", \"–\": \"-\", \"—\": \" - \", \"−\": \"-\",\n",
    "    \"…\": \"...\",\n",
    "}\n",
    "CO2_VARIANTS = [\"CO₂\", \"C0₂\", \"CO₂e\", \"CO2e\", \"tCO₂e\", \"tCO2e\"]\n",
    "\n",
    "# Regex patterns\n",
    "HEADER_PATTERNS = [\n",
    "    r\"^\\s*Page\\s+\\d+\\s*$\",\n",
    "    r\"^\\s*\\d{1,4}\\s*/\\s*\\d{1,4}\\s*$\",\n",
    "    r\"^\\s*\\d{1,4}\\s*$\",\n",
    "    r\"^HSBC Holdings plc Annual Report.*$\",\n",
    "    r\"^Google(’s|'s)? 20\\d{2} (Environmental|Sustainability).*\",\n",
    "    r\"^Nestl[eé] .*Sustainability.*$\",\n",
    "]\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\", re.I)\n",
    "BULLET_RE = re.compile(r\"^\\s*(?:[-•▪◦◻▶»]+|\\d+\\.)\\s+\")\n",
    "\n",
    "def normalize_unicode(s: str) -> str:\n",
    "    \"\"\"Normalize Unicode characters and replace ligatures.\"\"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    for k, v in LIGATURES.items():\n",
    "        s = s.replace(k, v)\n",
    "    for v in CO2_VARIANTS:\n",
    "        s = s.replace(v, \"CO2e\" if \"e\" in v.lower() else \"CO2\")\n",
    "    return s\n",
    "\n",
    "def fix_hyphenation(s: str) -> str:\n",
    "    \"\"\"Join words split across line breaks with hyphens.\"\"\"\n",
    "    return re.sub(r\"(?<=\\w)-\\n(?=\\w)\", \"\", s)\n",
    "\n",
    "def clean_text(raw: str) -> str:\n",
    "    \"\"\"Clean a raw text string from sustainability reports.\"\"\"\n",
    "    s = normalize_unicode(raw)\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = fix_hyphenation(s)\n",
    "    s = URL_RE.sub(\"\", s)\n",
    "\n",
    "    lines = s.split(\"\\n\")\n",
    "    out = []\n",
    "    for ln in lines:\n",
    "        if any(re.match(p, ln.strip(), flags=re.I) for p in HEADER_PATTERNS):\n",
    "            continue\n",
    "        out.append(ln.rstrip())\n",
    "    lines = out\n",
    "\n",
    "    # Rejoin broken lines into full paragraphs\n",
    "    joined = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if not line:\n",
    "            joined.append(\"\")\n",
    "            i += 1\n",
    "            continue\n",
    "        buf = line\n",
    "        while i + 1 < len(lines):\n",
    "            nxt = lines[i + 1].strip()\n",
    "            if not nxt or BULLET_RE.match(nxt) or re.search(r\"[.!?]$\", buf):\n",
    "                break\n",
    "            buf += \" \" + nxt\n",
    "            i += 1\n",
    "        joined.append(buf)\n",
    "        i += 1\n",
    "\n",
    "    cleaned = \"\\n\".join(joined).strip()\n",
    "    return cleaned\n",
    "\n",
    "# Process all TXT files in the input directory\n",
    "for fn in os.listdir(input_dir):\n",
    "    if not fn.endswith(\".txt\"):\n",
    "        continue\n",
    "    raw = Path(input_dir, fn).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    cleaned = clean_text(raw)\n",
    "    Path(output_dir, fn).write_text(cleaned, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Cleaning completed. Output directory:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d0186-5b5a-465b-b9ee-396c077d441d",
   "metadata": {},
   "source": [
    "### Creating a corpus by combining all files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1368849b-361d-4814-bb7f-4d2f41e7a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus created at: data/cleaned_v2/combined_corpus.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os, re, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Directories\n",
    "base = Path(\"data\")\n",
    "input_dir = base / \"cleaned_v2\"\n",
    "output_file = input_dir / \"combined_corpus.jsonl\"\n",
    "\n",
    "def parse_metadata(filename: str):\n",
    "    \"\"\"Extract company name and year from filename.\"\"\"\n",
    "    year_match = re.search(r\"(20\\d{2})\", filename)\n",
    "    year = int(year_match.group(1)) if year_match else None\n",
    "    company = None\n",
    "    if filename.lower().startswith(\"google\"):\n",
    "        company = \"Google\"\n",
    "    elif filename.lower().startswith(\"hsbc\"):\n",
    "        company = \"HSBC\"\n",
    "    elif filename.lower().startswith(\"nestle\"):\n",
    "        company = \"Nestle\"\n",
    "    return company, year\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "    for fn in sorted(os.listdir(input_dir)):\n",
    "        if not fn.endswith(\".txt\"):\n",
    "            continue\n",
    "        company, year = parse_metadata(fn)\n",
    "        text = Path(input_dir, fn).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        record = {\n",
    "            \"company\": company,\n",
    "            \"year\": year,\n",
    "            \"file\": fn,\n",
    "            \"text\": text\n",
    "        }\n",
    "        out.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Corpus created at:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee40478-8c57-44ea-8ec3-f0f6c7647815",
   "metadata": {},
   "source": [
    "### Making a quick simple sanity check to see everything works properly ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda4cb02-6029-461b-9edf-a95a37bbaa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 9\n",
      "Companies: ['Google' 'HSBC' 'Nestle']\n",
      "Years: [2022 2023 2024]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>2022</td>\n",
       "      <td>43444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>2023</td>\n",
       "      <td>347288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>2024</td>\n",
       "      <td>347750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2022</td>\n",
       "      <td>294158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2023</td>\n",
       "      <td>312433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2024</td>\n",
       "      <td>233796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nestle</td>\n",
       "      <td>2022</td>\n",
       "      <td>321825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nestle</td>\n",
       "      <td>2023</td>\n",
       "      <td>357262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nestle</td>\n",
       "      <td>2024</td>\n",
       "      <td>124295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company  year  n_chars  n_docs\n",
       "0  Google  2022    43444       1\n",
       "1  Google  2023   347288       1\n",
       "2  Google  2024   347750       1\n",
       "3    HSBC  2022   294158       1\n",
       "4    HSBC  2023   312433       1\n",
       "5    HSBC  2024   233796       1\n",
       "6  Nestle  2022   321825       1\n",
       "7  Nestle  2023   357262       1\n",
       "8  Nestle  2024   124295       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the combined corpus\n",
    "corpus_path = Path(\"data/cleaned_v2/combined_corpus.jsonl\")\n",
    "\n",
    "records = []\n",
    "with open(corpus_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        records.append(json.loads(line))\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Quick checks\n",
    "print(\"Total records:\", len(df))\n",
    "print(\"Companies:\", df['company'].unique())\n",
    "print(\"Years:\", df['year'].unique())\n",
    "\n",
    "# Basic stats\n",
    "summary = df.groupby([\"company\",\"year\"]).agg(\n",
    "    n_chars = (\"text\", lambda x: sum(len(t) for t in x)),\n",
    "    n_docs = (\"file\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "display(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
