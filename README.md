# Hybrid ESG Sentiment Analysis in Corporate Sustainability Reports: Integrating Transformers with Snippet-Based Lexicon Features

This repository contains the code and data preparation pipeline for our bachelor thesis project on hybrid ESG sentiment analysis in corporate sustainability reports.

## ðŸ“Š Pipeline Flowchart

![Hybrid ESG Pipeline](images/Flowchart.jpeg)

## Repository Structure
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_reports/                          # Extracted .txt files (starting point of pipeline)
â”‚   â”‚   â”œâ”€â”€ Google 2022.txt
â”‚   â”‚   â”œâ”€â”€ Google 2023.txt
â”‚   â”‚   â”œâ”€â”€ Google 2024.txt
â”‚   â”‚   â”œâ”€â”€ HSBC 2022.txt
â”‚   â”‚   â”œâ”€â”€ HSBC 2023.txt
â”‚   â”‚   â”œâ”€â”€ HSBC 2024.txt
â”‚   â”‚   â”œâ”€â”€ Nestle 2022.txt
â”‚   â”‚   â”œâ”€â”€ Nestle 2023.txt
â”‚   â”‚   â””â”€â”€ Nestle 2024.txt
â”‚   â””â”€â”€ cleaned_v2/
â”‚       â”œâ”€â”€ combined_corpus.jsonl             # Cleaned corpus with company/year/text
â”‚       â”œâ”€â”€ preprocessed_corpus.jsonl         # Sentence-level corpus (for BERT)
â”‚       â””â”€â”€ preprocessed_with_lemma.jsonl     # Lemmatized/token corpus (for lexicon & snippet analysis)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_cleaning_and_corpus.ipynb     # Cleaning and corpus creation
â”‚   â””â”€â”€ 02_preprocessing.ipynb                # Preprocessing: normalization, sentence splitting, lemma
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Pipeline Overview
1. **Data Cleaning & Corpus Creation**
   - Extracted 9 sustainability reports (Google, HSBC, NestlÃ©; 2022â€“2024).
   - **Note:** Original PDF reports are *not* included in this repository due to copyright restrictions.  
     - They are publicly available on the companies' websites.  
     - The pipeline starts from the already extracted `.txt` files under `data/raw_reports/`.  
   - From these `.txt` files, we create a structured JSONL corpus with `company`, `year`, `file`, and `text`.

2. **Preprocessing**
   - Normalization (lowercasing, number/unit handling).
   - Sentence splitting (for transformer input).
   - Stopword removal + lemmatization (for lexicon/snippet analysis).

## Current Status
- âœ… Data cleaning completed.  
- âœ… Corpus structured and validated.  
- âœ… Preprocessing completed (sentence-level + lemmatized corpora).  

## Next Steps
- Baseline sentiment analysis with DistilBERT/BERT.  
- Snippet integration (ESG-specific lexicons, negation handling, intensifiers).  
- Evaluation (distributional analysis, inter-model agreement, case studies).  

---

### ðŸ“Œ Reproducibility Note
This repository is designed to be fully reproducible **starting from the extracted `.txt` files** provided in `data/raw_reports/`.  
Anyone cloning this repository can run the notebooks step by step and obtain the same corpora and preprocessing outputs, without needing the original PDF files.
